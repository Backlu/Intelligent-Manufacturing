{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case - Facial Beauty\n",
    "\n",
    "Copyright Â© 2019 Hsu Shih-Chieh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from datasets import load_facialbeauty\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications import MobileNet, MobileNetV2,DenseNet169, NASNetLarge, InceptionResNetV2, ResNet50\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "#from efficientnet import EfficientNetB0\n",
    "\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger, TensorBoard, ReduceLROnPlateau, LambdaCallback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_facialbeauty\n",
    "plt.rcParams['font.size'] = 9\n",
    "plt.rcParams['figure.figsize'] = (9,9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_facialbeauty(qty=1000)\n",
    "print(data.DESCR)\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(data.data, data.target, test_size=0.2, random_state=40)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_tr, y_tr, test_size=0.2, random_state=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (350, 350, 3)\n",
    "base_model=InceptionResNetV2(weights='imagenet',include_top=False, input_shape=input_shape) \n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "preds=Dense(1)(x) #final layer with softmax activation\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "#sgd = SGD(lr= 0.01, decay=7e-05, momentum=0.5, nesterov=True)\n",
    "model.compile(optimizer='adam', loss='mse')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgAug = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#    width_shift_range=0.001,\n",
    "#    height_shift_range=0.001,\n",
    ")\n",
    "\n",
    "\n",
    "#imgAug.fit(X_tr)\n",
    "batch=21\n",
    "dgen_val = imgAug.flow(X_val, y_val, batch_size=batch)\n",
    "dgen_tr = imgAug.flow(X_tr, y_tr, batch_size=batch)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, mode='min', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "#_, checkpoint_file = tempfile.mkstemp('.h5')\n",
    "#print('checkpoint_file: ',checkpoint_file)\n",
    "#checkpointer=ModelCheckpoint(monitor='val_loss',filepath=checkpoint_file, verbose=1, save_best_only=True, save_weights_only=False)\n",
    "#tboard = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "callbacks = [reduce_lr, early_stop]\n",
    "history = model.fit_generator(dgen_tr, steps_per_epoch=X_tr.shape[0]//batch, validation_steps=X_val.shape[0]//batch, epochs=50, validation_data=dgen_val, callbacks=callbacks) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Test Data Peroformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAug2 = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "dgen_ts = imgAug2.flow(X_ts, shuffle=False, batch_size=100)\n",
    "preds = model.predict_generator(dgen_ts, steps=X_ts.shape[0]//100)\n",
    "\n",
    "plt.scatter(y_ts, preds)\n",
    "plt.plot(y_ts, y_ts, 'ro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_test_samples = X_ts.shape[0]\n",
    "nb_rows, nb_cols = 5, 5\n",
    "plt.figure(figsize=(10,10))\n",
    "for k in range(nb_rows * nb_cols):\n",
    "    i = randint(0, nb_test_samples - 1)\n",
    "    pred = model.predict(np.expand_dims(preprocess_input(X_ts[i].copy()), axis=0))\n",
    "    plt.subplot(nb_rows, nb_cols, k+1)\n",
    "    plt.imshow(X_ts[i].astype(np.uint8))\n",
    "    plt.title(\"p:%.2f / a:%.2f\" % (pred[0][0], y_ts[i]))\n",
    "    plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow lite model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save model to tflite format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = 'tfmodel/facialbeauty.tflite'\n",
    "modelname='model/facialbeauty.h5'\n",
    "model.save(modelname)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(modelname, input_arrays=['input_4'], input_shapes={'input_4':[None,input_shape[0],input_shape[1],input_shape[2]]})\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    f.write(tflite_model)   \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = 'tfmodel/facialbeauty.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]      \n",
    "nb_test_samples = X_ts.shape[0]\n",
    "nb_rows, nb_cols = 5, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**inference by tflite model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = 'tfmodel/facialbeauty.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]      \n",
    "nb_test_samples = X_ts.shape[0]\n",
    "nb_rows, nb_cols = 5, 5\n",
    "    \n",
    "preds=[]\n",
    "idxs=[]\n",
    "for k in range(nb_rows * nb_cols):\n",
    "    i = randint(0, nb_test_samples - 1)\n",
    "    idxs.append(i)\n",
    "    interpreter.set_tensor(input_index, np.expand_dims(preprocess_input(X_ts[i].copy()), axis=0))\n",
    "    interpreter.invoke()\n",
    "    pred = interpreter.get_tensor(output_index)\n",
    "    preds.append(pred.flatten()[0])\n",
    "\n",
    "preds, idxs = zip(*sorted(zip(preds, idxs), reverse=True))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for k in range(nb_rows * nb_cols):\n",
    "    plt.subplot(nb_rows, nb_cols, k+1)\n",
    "    plt.imshow(X_ts[idxs[k]].astype(np.uint8))\n",
    "    plt.title(\"p:%.2f\" % (preds[k]))\n",
    "    plt.axis('off')    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = data.test_data\n",
    "\n",
    "tflite_model_file = 'tfmodel/facialbeauty.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]      \n",
    "nb_test_samples = X_new.shape[0]\n",
    "nb_rows, nb_cols = 6, 6\n",
    "preds=[]\n",
    "for k in range(nb_rows * nb_cols):\n",
    "    if k>=X_new.shape[0]:\n",
    "        break\n",
    "    interpreter.set_tensor(input_index, np.expand_dims(preprocess_input(X_new[k].copy()), axis=0))\n",
    "    interpreter.invoke()\n",
    "    pred = interpreter.get_tensor(output_index)\n",
    "    preds.append(pred.flatten()[0])\n",
    "\n",
    "preds, idxs = zip(*sorted(zip(preds, list(range(len(preds)))), reverse=True))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for k in range(nb_rows * nb_cols):\n",
    "    if k>=X_new.shape[0]:\n",
    "        break    \n",
    "    plt.subplot(nb_rows, nb_cols, k+1)\n",
    "    plt.imshow(X_new[idxs[k]].astype(np.uint8))\n",
    "    plt.title(\"beauty score:%.2f\" % (preds[k]))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = data.test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
